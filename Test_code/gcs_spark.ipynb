{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3307b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "425534ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from prefect import task\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql import DataFrame as SparkDataFrame\n",
    "import contextlib\n",
    "import os\n",
    "from prefect import flow\n",
    "from pyspark import SparkConf,SparkContext\n",
    "from prefect.blocks.system import Secret\n",
    "import pandas as pd\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0fc091",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/Users/og/Desktop/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "551c1425",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def get_spark_session(json, app_name='economic_data'):\n",
    "    \"\"\"\n",
    "    Function that is wrapped by context manager\n",
    "    Args:\n",
    "      - conf(SparkConf): It is the configuration for the Spark session\n",
    "    \"\"\"\n",
    "    json_path = json\n",
    "    \n",
    "    conf = SparkConf() \\\n",
    "        .setMaster('local[*]') \\\n",
    "        .setAppName(app_name) \\\n",
    "        .set(\"spark.jars\", \"/Users/og/Downloads/gcs-connector-hadoop2-2.2.15-shaded.jar\") \\\n",
    "        .set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "        .set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", json_path)\n",
    "\n",
    "    spark = SparkSession.builder \\\n",
    "        .config(conf=conf) \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    hadoop_conf = spark.sparkContext._jsc.hadoopConfiguration()\n",
    "    hadoop_conf.set(\"fs.AbstractFileSystem.gs.impl\",  \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "    hadoop_conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "    hadoop_conf.set(\"fs.gs.auth.service.account.json.keyfile\", json_path)\n",
    "    hadoop_conf.set(\"fs.gs.auth.service.account.enable\", \"true\")\n",
    "\n",
    "    try:\n",
    "        yield spark\n",
    "    finally:\n",
    "        spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b847c3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_gcp_parquet(years: List[int], bucket: str, base_path: str, spark: SparkSession):\n",
    "    dfs = []\n",
    "    for year in years:\n",
    "        file_path = f'{base_path}{year}_California_city_economic_data.parquet'\n",
    "        df = spark.read.parquet(f'gs://{bucket}/{file_path}')\n",
    "        dfs.append(df)\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60b2f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def union_dataframes(dfs: List[SparkDataFrame]) -> SparkDataFrame:\n",
    "    meta_df = None\n",
    "    for df in dfs:\n",
    "        if meta_df is None:\n",
    "            meta_df = df \n",
    "        else:\n",
    "            meta_df = meta_df.union(df)\n",
    "    return meta_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9498dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline(json_path):\n",
    "    bucket = 'de_final_project_bucket'\n",
    "    base_path = 'data/economic/city/'\n",
    "    years = range(2020,2021)\n",
    "    # Setting up the Spark cluster\n",
    "    with get_spark_session(json=json_path,app_name='test') as spark_session:\n",
    "\n",
    "        dfs = retrieve_gcp_parquet(years=years,\n",
    "                                bucket=bucket,\n",
    "                                base_path=base_path,\n",
    "                                spark=spark_session)\n",
    "        meta_df = union_dataframes(dfs)\n",
    "        \n",
    "        meta_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6936c083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+--------------------+----------+-------------+----------------+-----------------+-------------+------------------+----------------+\n",
      "|year|      state|                city|population|   median_age|household_income|per_capita_income|poverty_count|unemployment_count|employment_count|\n",
      "+----+-----------+--------------------+----------+-------------+----------------+-----------------+-------------+------------------+----------------+\n",
      "|2020| California|     Home Garden CDP|    1590.0|         26.3|         35197.0|          13888.0|        455.0|              88.0|           486.0|\n",
      "|2020| California|    Home Gardens CDP|   12027.0|         34.1|         67716.0|          23281.0|       1759.0|             244.0|          5321.0|\n",
      "|2020| California|        Homeland CDP|    7613.0|         33.9|         53008.0|          19935.0|        831.0|             324.0|          3130.0|\n",
      "|2020| California|Homestead Valley CDP|    2619.0|         55.4|         33993.0|          21077.0|        550.0|             136.0|           759.0|\n",
      "|2020| California| Homewood Canyon CDP|     241.0|         53.2|   -6.66666666E8|          38579.0|          0.0|               0.0|           166.0|\n",
      "|2020| California|          Honcut CDP|     172.0|         44.2|   -6.66666666E8|          54144.0|          0.0|              31.0|            73.0|\n",
      "|2020| California|            Hood CDP|     289.0|         45.2|         58571.0|          19350.0|         15.0|              15.0|           120.0|\n",
      "|2020| California|           Hoopa CDP|    3348.0|         36.7|         29615.0|          15736.0|       1148.0|              96.0|           917.0|\n",
      "|2020| California|         Hopland CDP|     899.0|         47.5|         57019.0|          27424.0|        161.0|              71.0|           386.0|\n",
      "|2020| California|       Hornbrook CDP|     243.0|         55.9|         27917.0|          20599.0|         82.0|              32.0|            63.0|\n",
      "|2020| California|        Hornitos CDP|      74.0|         52.1|   -6.66666666E8|             null|          0.0|               0.0|            32.0|\n",
      "|2020| California|        Hughson city|    7545.0|         34.4|         83231.0|          32750.0|        667.0|             227.0|          3403.0|\n",
      "|2020| California|   Humboldt Hill CDP|    3435.0|         40.3|         74594.0|          35790.0|        287.0|             256.0|          1525.0|\n",
      "|2020| California|Huntington Beach ...|  199778.0|         43.2|         97469.0|          50625.0|      15661.0|            5356.0|        105795.0|\n",
      "|2020| California|Huntington Park city|   57761.0|         31.7|         46738.0|          16386.0|      12445.0|            2952.0|         26153.0|\n",
      "|2020| California|          Huron city|    7084.0|         28.1|         31429.0|          13114.0|       2923.0|             580.0|          2494.0|\n",
      "|2020| California|         Hyampom CDP|     124.0|         61.2|   -6.66666666E8|          19399.0|         19.0|               0.0|             0.0|\n",
      "|2020| California|      Hydesville CDP|    1051.0|         57.5|         55521.0|          35005.0|        207.0|               8.0|           464.0|\n",
      "|2020| California|       Hypericum CDP|     160.0|         40.5|   -6.66666666E8|          13864.0|          0.0|               0.0|            56.0|\n",
      "|2020| California|        Idlewild CDP|       0.0|-6.66666666E8|   -6.66666666E8|    -6.66666666E8|          0.0|               0.0|             0.0|\n",
      "+----+-----------+--------------------+----------+-------------+----------------+-----------------+-------------+------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "json = 'de-final-project-388703-0bbc1822d023.json'\n",
    "meta_df = data_pipeline(json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee1eb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = spark.read.parquet('gs://de_final_project_bucket/data/demographic/city/*_Florida_city_demographic_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69915bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_count = len(meta_df.columns)\n",
    "print('Column Count:', column_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cce1185",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_count = meta_df.count()\n",
    "print('Row Count:', row_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a885d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
